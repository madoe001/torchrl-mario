{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxQq7CtVglDIWGWtHayN9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madoe001/torchrl-mario/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ck8lkaJhLvW8",
        "outputId": "f53046d9-626d-453f-8369-27a9d2d5f1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connecting to ppa.laun\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: gym-super-mario-bros==7.3.1 in /usr/local/lib/python3.10/dist-packages (7.3.1)\n",
            "Requirement already satisfied: nes-py>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from gym-super-mario-bros==7.3.1) (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (1.22.4)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (1.5.11)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.2->gym-super-mario-bros==7.3.1) (0.0.8)\n",
            "Requirement already satisfied: nes_py in /usr/local/lib/python3.10/dist-packages (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.22.4)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.5.11)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
            "Collecting gym==0.24.1\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.24.1) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.24.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.24.1) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793136 sha256=2375e54c13b30c5a51225cea244b9a0e8ce6f33231a53a95ebfa2573a8498fc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/fb/19/388995b88cb551717a8dff40c889172cd12fadf994216a0a22\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.24.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: pyglet==1.5.11 in /usr/local/lib/python3.10/dist-packages (1.5.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (23.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg > /dev/null\n",
        "!pip3 install imageio > /dev/null\n",
        "!pip3 install gym-super-mario-bros==7.3.1\n",
        "!pip3 install nes_py\n",
        "!pip3 install gym==0.24.1\n",
        "!pip3 install pyvirtualdisplay\n",
        "!pip install pyglet==1.5.11\n",
        "!pip3 install torch torchvision torchaudio tensorboard moviepy tensordict torchrl\n",
        "# !pip3 install git+https://github.com/Farama-Foundation/stable-retro.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from tensordict import TensorDictBase\n",
        "import retro\n",
        "import imageio\n",
        "import PIL.Image\n",
        "import torch\n",
        "import itertools\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs import (check_env_specs, TransformedEnv, Compose, Resize, ToTensorImage, GrayScale, CatFrames,\n",
        "                          NoopResetEnv, StepCounter, DoubleToFloat, ObservationNorm, ExplorationType, RewardSum,\n",
        "                          RewardScaling, FrameSkipTransform,\n",
        "                          set_exploration_type)\n",
        "from torchrl.envs.libs.gym import GymWrapper\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import OneHotCategorical\n",
        "from torch import nn\n",
        "from torchrl.modules.models import ConvNet, MLP\n",
        "from torchrl.modules import ProbabilisticActor, ValueOperator, ActorValueOperator\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from torchrl.record.loggers.tensorboard import TensorboardLogger\n",
        "from torchrl.record import VideoRecorder\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import (BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, BinaryDiscreteTensorSpec)\n",
        "\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "import pyvirtualdisplay\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D69nmCyEjTwP",
        "outputId": "5a15c059-566d-42d2-acd6-d74138808b22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install freeglut3-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosoqP-I5-64",
        "outputId": "44705f48-c7cc-4e6d-912b-d0b455ac1802"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  drive.mount('/content/drive')\n",
        "  !python3 -m retro.import \"/content/drive/MyDrive/ROMS/\"\n",
        "else:\n",
        "  !python3 -m retro.import \".\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATrWWtejLxMW",
        "outputId": "ca1726ee-31b6-430d-f212-db7e20ddad73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Importing SuperMarioBros-Nes\n",
            "Importing SuperMarioBros-Nes\n",
            "Imported 2 games\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "gym.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jbZXiuBId0pW",
        "outputId": "baa0b81e-1827-4819-c266-91e46dc2c4d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.25.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ],
      "metadata": {
        "id": "RAmlIKeKdO1S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym_super_mario_bros.make('SuperMarioBros-v3', new_step_api=True, render_mode=\"rgb_array\")\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "dh6gn4lXptHu",
        "outputId": "3f6ec05b-fcaa-42b1-9a02-6dc290e33723"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:657: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3ddb586de412>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym_super_mario_bros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SuperMarioBros-v3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_step_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJoypadSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIMPLE_MOVEMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m             )\n\u001b[1;32m    673\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;31m# Copies the environment creation specification and kwargs to add to the environment specification details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         if (\n",
            "\u001b[0;31mTypeError\u001b[0m: SuperMarioBrosEnv.__init__() got an unexpected keyword argument 'render_mode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "done = True\n",
        "truncate = True\n",
        "\n",
        "for i in range(100):\n",
        "    action = env.action_space.sample()\n",
        "    _, reward, done, truncate, info = env.step(action)\n",
        "    print(f\"{action}: {reward}\")\n",
        "print(env.render())\n",
        "# img = PIL.Image.fromarray(env.render())\n",
        "# img\n",
        "# for action in range(env.action_space.n):\n",
        "#     for step in range(10):\n",
        "#         if done | truncate:\n",
        "#             state = env.reset()\n",
        "#         _, reward, done, truncate, info = env.step(action)\n",
        "#         print(reward)"
      ],
      "metadata": {
        "id": "V_dLAKsapujN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space)"
      ],
      "metadata": {
        "id": "SW_jkGtKpw0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(1000):\n",
        "    if done | truncate:\n",
        "        print(\"RESET FUNCTION\")\n",
        "        state = env.reset()\n",
        "    action = env.action_space.sample()\n",
        "    _, reward, done, truncate, info = env.step(action)\n",
        "    # print(done, truncate, reward)\n",
        "    # if step % 4 == 0:\n",
        "    #    display(PIL.Image.fromarray(env.render()))\n",
        "img = PIL.Image.fromarray(env.render())\n",
        "# env.close()\n",
        "img\n",
        "env.reward_range"
      ],
      "metadata": {
        "id": "_9WAbcetpy5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparams\n",
        "num_cells = 256  # @param\n",
        "lr = 3e-4  # @param\n",
        "max_grad_norm = 1.0  # @param\n",
        "\n",
        "#FrameSkipping\n",
        "frame_skip = 4  # @param\n",
        "frames_per_batch = 1000 // frame_skip  # @param\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 1_000_000 // frame_skip  # @param\n",
        "\n",
        "sub_batch_size = 64  # @param cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 1  # @param optimisation steps per batch of data collected\n",
        "clip_epsilon = (\n",
        "    0.2  # @param clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "gamma = 0.99  # @param\n",
        "lmbda = 0.95  # @param\n",
        "entropy_eps = 1e-4  # @param"
      ],
      "metadata": {
        "id": "GBfV-SXppzjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.has_cuda else 'cpu'\n",
        "\n",
        "print(f'Using device {device}')"
      ],
      "metadata": {
        "id": "-gv_gf4mpzl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymWrapper(env, device=device, frame_skip=4)"
      ],
      "metadata": {
        "id": "CYplXPYIpzoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation_spec:\", base_env.observation_spec)\n",
        "print(\"state_spec:\", base_env.state_spec)\n",
        "print(\"reward_spec:\", base_env.reward_spec)\n",
        "logger = TensorboardLogger(\"TEST\", log_dir=\"./logs\")\n",
        "recorder = VideoRecorder(logger, tag=\"SuperMario\", )\n",
        "\n",
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # recorder,\n",
        "        ActionResetEnv(noops=100,\n",
        "                       action=6,\n",
        "                       ),\n",
        "        RewardScaling(0.0, 5.0),\n",
        "        # NoopResetEnv(noops=1_000),\n",
        "        FrameSkipTransform(frame_skip=4),\n",
        "        ToTensorImage(),\n",
        "        GrayScale(),\n",
        "        Resize(84, 84),\n",
        "        CatFrames(N=4, dim=-3),\n",
        "        StepCounter(),\n",
        "        # RewardSum(),\n",
        "        ObservationNorm(standard_normal=True, in_keys=['pixels']),\n",
        "        DoubleToFloat(in_keys=[\"pixels\"]),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "PK0H8QK-pzqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observation_norm_wrapper_index = 8\n",
        "env.transform[observation_norm_wrapper_index].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
        "print(\"normalization constant shape:\", env.transform[observation_norm_wrapper_index].loc.shape)"
      ],
      "metadata": {
        "id": "riK9IByUqEQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "-M_-uB3yqFUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_outputs = env.action_spec.space.n\n",
        "input_shape = env.observation_spec[\"pixels\"].shape"
      ],
      "metadata": {
        "id": "NA0awRGBqGcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_features = env.action_spec.shape[0]\n",
        "print(out_features)"
      ],
      "metadata": {
        "id": "f479aReJqHlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_cnn = ConvNet(\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    num_cells=[32, 64, 64],\n",
        "    kernel_sizes=[8, 4, 3],\n",
        "    strides=[4, 2, 1],\n",
        ")\n",
        "\n",
        "common_cnn_output = common_cnn(torch.ones(input_shape))\n",
        "common_mlp = MLP(\n",
        "    in_features=common_cnn_output.shape[-1],\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    activate_last_layer=True,\n",
        "    out_features=512,\n",
        "    num_cells=[],\n",
        ")\n",
        "common_mlp_output = common_mlp(common_cnn_output)\n",
        "\n",
        "# Define shared net as TensorDictModule\n",
        "common_module = TensorDictModule(\n",
        "    module=torch.nn.Sequential(common_cnn, common_mlp),\n",
        "    in_keys=[\"pixels\"],\n",
        "    out_keys=[\"common_features\"],\n",
        ")\n",
        "\n",
        "# Define on head for the policy\n",
        "policy_net = MLP(\n",
        "    in_features=common_mlp_output.shape[-1],\n",
        "    out_features=num_outputs,\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    num_cells=[256],\n",
        ")\n",
        "policy_module = TensorDictModule(\n",
        "    module=policy_net,\n",
        "    in_keys=[\"common_features\"],\n",
        "    out_keys=[\"logits\"],\n",
        ")\n",
        "\n",
        "# Add probabilistic sampling of the actions\n",
        "policy_module = ProbabilisticActor(\n",
        "    policy_module,\n",
        "    in_keys=[\"logits\"],\n",
        "    spec=CompositeSpec(action=env.action_spec),\n",
        "    # safe=True,\n",
        "    distribution_class=OneHotCategorical,\n",
        "    distribution_kwargs={},\n",
        "    return_log_prob=True,\n",
        "    default_interaction_type=ExplorationType.RANDOM,\n",
        ")\n",
        "\n",
        "# Define another head for the value\n",
        "value_net = MLP(\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    in_features=common_mlp_output.shape[-1],\n",
        "    out_features=1,\n",
        "    num_cells=[256],\n",
        ")\n",
        "value_module = ValueOperator(\n",
        "    value_net,\n",
        "    in_keys=[\"common_features\"],\n",
        ")"
      ],
      "metadata": {
        "id": "Z7gPCBCUqIf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_critic = ActorValueOperator(\n",
        "    common_operator=common_module,\n",
        "    value_operator=value_module,\n",
        "    policy_operator=policy_module\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "dj5UygmTqKO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    td = env.rollout(max_steps=1000, break_when_any_done=False)\n",
        "    td = actor_critic(td)"
      ],
      "metadata": {
        "id": "muv30hWcqLp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    actor_critic.get_policy_operator(),\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "Q1iQvbHAqMc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "xREjzDFCqNi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma,\n",
        "    lmbda=lmbda,\n",
        "    value_network=actor_critic.get_value_operator(),\n",
        "    average_gae=True\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor=actor_critic.get_policy_operator(),\n",
        "    critic=actor_critic.get_value_head(),\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    value_target_key=advantage_module.value_target_key,\n",
        "    gamma=0.99,\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)"
      ],
      "metadata": {
        "id": "sYABG3CoqPHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "env.reset()\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                    loss_vals[\"loss_objective\"]\n",
        "                    + loss_vals[\"loss_critic\"]\n",
        "                    + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "\n",
        "   #  recorder.dump(f\"Episode_{i}\")\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, actor_critic.get_policy_operator())\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))"
      ],
      "metadata": {
        "id": "_jRcinbdqQgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JKmCfQyxqSpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}