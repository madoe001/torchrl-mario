{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcvFBStTaZ9N9j6DIjt/Vn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madoe001/torchrl-mario/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck8lkaJhLvW8",
        "outputId": "7c59c9d0-4c09-46b7-e6d0-31be5f28c77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym-super-mario-bros in /usr/local/lib/python3.10/dist-packages (7.4.0)\n",
            "Requirement already satisfied: nes-py>=8.1.4 in /usr/local/lib/python3.10/dist-packages (from gym-super-mario-bros) (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.22.4)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.21)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (0.0.8)\n",
            "Requirement already satisfied: nes_py in /usr/local/lib/python3.10/dist-packages (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.22.4)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.5.21)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (23.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gym-super-mario-bros\n",
        "!pip3 install nes_py\n",
        "!pip3 install pyvirtualdisplay\n",
        "!pip3 install torch torchvision torchaudio tensorboard moviepy tensordict torchrl\n",
        "# !pip3 install git+https://github.com/Farama-Foundation/stable-retro.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from tensordict import TensorDictBase\n",
        "import retro\n",
        "import PIL.Image\n",
        "import torch\n",
        "import itertools\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs import (check_env_specs, TransformedEnv, Compose, Resize, ToTensorImage, GrayScale, CatFrames,\n",
        "                          NoopResetEnv, StepCounter, DoubleToFloat, ObservationNorm, ExplorationType, RewardSum,\n",
        "                          RewardScaling, FrameSkipTransform,\n",
        "                          set_exploration_type)\n",
        "from torchrl.envs.libs.gym import GymWrapper\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import OneHotCategorical\n",
        "from torch import nn\n",
        "from torchrl.modules.models import ConvNet, MLP\n",
        "from torchrl.modules import ProbabilisticActor, ValueOperator, ActorValueOperator\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from torchrl.record.loggers.tensorboard import TensorboardLogger\n",
        "from torchrl.record import VideoRecorder\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import (BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, BinaryDiscreteTensorSpec)\n",
        "\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
      ],
      "metadata": {
        "id": "D69nmCyEjTwP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  drive.mount('/content/drive')\n",
        "  !python3 -m retro.import \"/content/drive/MyDrive/ROMS/\"\n",
        "else:\n",
        "  !python3 -m retro.import \".\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATrWWtejLxMW",
        "outputId": "971d9b00-23c7-4018-f869-538f5ca2fb1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  self._read_thread.setDaemon(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Importing SuperMarioBros-Nes\n",
            "Importing SuperMarioBros-Nes\n",
            "Imported 2 games\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "gym.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "jbZXiuBId0pW",
        "outputId": "cccb92e9-f324-4497-9132-bb71b3df94ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.25.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAmlIKeKdO1S",
        "outputId": "9b916a80-4ce9-4ca8-85a3-09303fe96523"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym_super_mario_bros.make('SuperMarioBros-v3', new_step_api=True)\n",
        "# env = JoypadSpace(env, SIMPLE_MOVEMENT)\n"
      ],
      "metadata": {
        "id": "dh6gn4lXptHu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "done = True\n",
        "truncate = True\n",
        "\n",
        "for i in range(100):\n",
        "    action = env.action_space.sample()\n",
        "    _, reward, done, truncate, info = env.step(action)\n",
        "    print(f\"{action}: {reward}\")\n",
        "env.render()\n",
        "# img = PIL.Image.fromarray(env.render())\n",
        "# img\n",
        "# for action in range(env.action_space.n):\n",
        "#     for step in range(10):\n",
        "#         if done | truncate:\n",
        "#             state = env.reset()\n",
        "#         _, reward, done, truncate, info = env.step(action)\n",
        "#         print(reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_dLAKsapujN",
        "outputId": "82235f07-398c-410d-c5a3-ebdea41862f5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171: 0.0\n",
            "84: 0.0\n",
            "251: -1.0\n",
            "56: 0.0\n",
            "248: 0.0\n",
            "165: 0.0\n",
            "66: 1.0\n",
            "120: 0.0\n",
            "137: 0.0\n",
            "159: 0.0\n",
            "35: 0.0\n",
            "10: 0.0\n",
            "141: 0.0\n",
            "110: 0.0\n",
            "242: 0.0\n",
            "82: 0.0\n",
            "182: 0.0\n",
            "198: 0.0\n",
            "170: 0.0\n",
            "192: 1.0\n",
            "53: 0.0\n",
            "96: 0.0\n",
            "222: -1.0\n",
            "171: 0.0\n",
            "42: 0.0\n",
            "173: 0.0\n",
            "84: 0.0\n",
            "247: 0.0\n",
            "168: 0.0\n",
            "210: 0.0\n",
            "253: 1.0\n",
            "90: 0.0\n",
            "67: 0.0\n",
            "173: 0.0\n",
            "197: 1.0\n",
            "24: 0.0\n",
            "254: 0.0\n",
            "138: 1.0\n",
            "243: 0.0\n",
            "177: 1.0\n",
            "245: 0.0\n",
            "176: 1.0\n",
            "104: 1.0\n",
            "221: 0.0\n",
            "252: 0.0\n",
            "59: 0.0\n",
            "130: 0.0\n",
            "112: 0.0\n",
            "65: 0.0\n",
            "229: 0.0\n",
            "26: 0.0\n",
            "38: 0.0\n",
            "48: 0.0\n",
            "218: 0.0\n",
            "137: 0.0\n",
            "43: 0.0\n",
            "177: 0.0\n",
            "175: 0.0\n",
            "104: 0.0\n",
            "118: 0.0\n",
            "242: 0.0\n",
            "0: 0.0\n",
            "132: 0.0\n",
            "214: 0.0\n",
            "95: 0.0\n",
            "100: 0.0\n",
            "222: 0.0\n",
            "172: 0.0\n",
            "163: 0.0\n",
            "221: 0.0\n",
            "166: 0.0\n",
            "174: 0.0\n",
            "255: 0.0\n",
            "173: 0.0\n",
            "84: 0.0\n",
            "16: 0.0\n",
            "118: 0.0\n",
            "174: 0.0\n",
            "166: 0.0\n",
            "187: 0.0\n",
            "162: 0.0\n",
            "15: 0.0\n",
            "174: 0.0\n",
            "104: 0.0\n",
            "71: 0.0\n",
            "249: 0.0\n",
            "198: 0.0\n",
            "8: 0.0\n",
            "40: 0.0\n",
            "191: 0.0\n",
            "97: 0.0\n",
            "38: 0.0\n",
            "218: 0.0\n",
            "117: 0.0\n",
            "224: 1.0\n",
            "36: 1.0\n",
            "17: -1.0\n",
            "90: 1.0\n",
            "49: 1.0\n",
            "195: 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NoSuchDisplayException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-62ff9028c3f5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{action}: {reward}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# img = PIL.Image.fromarray(env.render())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     ) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m         \u001b[0;34m\"\"\"Renders the environment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     ) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    420\u001b[0m         \u001b[0;34m\"\"\"Renders the environment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/wrappers/env_checker.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_render_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrender_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nes_py/nes_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 )\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# show the screen on the image viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nes_py/_image_viewer.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# open the window if it isn't open already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;31m# prepare the window for the next frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nes_py/_image_viewer.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;34m\"\"\"Open the window.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# create a window for this image viewer instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         self._window = self.pyglet.window.Window(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, file_drops, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW_jkGtKpw0U",
        "outputId": "025d648b-2a9e-45d0-9a94-7706f0740c84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(1000):\n",
        "    if done | truncate:\n",
        "        print(\"RESET FUNCTION\")\n",
        "        state = env.reset()\n",
        "    action = env.action_space.sample()\n",
        "    _, reward, done, truncate, info = env.step(action)\n",
        "    # print(done, truncate, reward)\n",
        "    # if step % 4 == 0:\n",
        "    #    display(PIL.Image.fromarray(env.render()))\n",
        "img = PIL.Image.fromarray(env.render())\n",
        "# env.close()\n",
        "img\n",
        "env.reward_range"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9WAbcetpy5z",
        "outputId": "c836da7e-21e4-415f-8444-96ebd64122b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-inf, inf)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparams\n",
        "num_cells = 256  # @param\n",
        "lr = 3e-4  # @param\n",
        "max_grad_norm = 1.0  # @param\n",
        "\n",
        "#FrameSkipping\n",
        "frame_skip = 4  # @param\n",
        "frames_per_batch = 1000 // frame_skip  # @param\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 1_000_000 // frame_skip  # @param\n",
        "\n",
        "sub_batch_size = 64  # @param cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 1  # @param optimisation steps per batch of data collected\n",
        "clip_epsilon = (\n",
        "    0.2  # @param clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "gamma = 0.99  # @param\n",
        "lmbda = 0.95  # @param\n",
        "entropy_eps = 1e-4  # @param"
      ],
      "metadata": {
        "id": "GBfV-SXppzjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.has_cuda else 'cpu'\n",
        "\n",
        "print(f'Using device {device}')"
      ],
      "metadata": {
        "id": "-gv_gf4mpzl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymWrapper(env, device=device, frame_skip=4)"
      ],
      "metadata": {
        "id": "CYplXPYIpzoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation_spec:\", base_env.observation_spec)\n",
        "print(\"state_spec:\", base_env.state_spec)\n",
        "print(\"reward_spec:\", base_env.reward_spec)\n",
        "logger = TensorboardLogger(\"TEST\", log_dir=\"./logs\")\n",
        "recorder = VideoRecorder(logger, tag=\"SuperMario\", )\n",
        "\n",
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # recorder,\n",
        "        ActionResetEnv(noops=100,\n",
        "                       action=6,\n",
        "                       ),\n",
        "        RewardScaling(0.0, 5.0),\n",
        "        # NoopResetEnv(noops=1_000),\n",
        "        FrameSkipTransform(frame_skip=4),\n",
        "        ToTensorImage(),\n",
        "        GrayScale(),\n",
        "        Resize(84, 84),\n",
        "        CatFrames(N=4, dim=-3),\n",
        "        StepCounter(),\n",
        "        # RewardSum(),\n",
        "        ObservationNorm(standard_normal=True, in_keys=['pixels']),\n",
        "        DoubleToFloat(in_keys=[\"pixels\"]),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "PK0H8QK-pzqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observation_norm_wrapper_index = 8\n",
        "env.transform[observation_norm_wrapper_index].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
        "print(\"normalization constant shape:\", env.transform[observation_norm_wrapper_index].loc.shape)"
      ],
      "metadata": {
        "id": "riK9IByUqEQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "-M_-uB3yqFUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_outputs = env.action_spec.space.n\n",
        "input_shape = env.observation_spec[\"pixels\"].shape"
      ],
      "metadata": {
        "id": "NA0awRGBqGcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_features = env.action_spec.shape[0]\n",
        "print(out_features)"
      ],
      "metadata": {
        "id": "f479aReJqHlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_cnn = ConvNet(\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    num_cells=[32, 64, 64],\n",
        "    kernel_sizes=[8, 4, 3],\n",
        "    strides=[4, 2, 1],\n",
        ")\n",
        "\n",
        "common_cnn_output = common_cnn(torch.ones(input_shape))\n",
        "common_mlp = MLP(\n",
        "    in_features=common_cnn_output.shape[-1],\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    activate_last_layer=True,\n",
        "    out_features=512,\n",
        "    num_cells=[],\n",
        ")\n",
        "common_mlp_output = common_mlp(common_cnn_output)\n",
        "\n",
        "# Define shared net as TensorDictModule\n",
        "common_module = TensorDictModule(\n",
        "    module=torch.nn.Sequential(common_cnn, common_mlp),\n",
        "    in_keys=[\"pixels\"],\n",
        "    out_keys=[\"common_features\"],\n",
        ")\n",
        "\n",
        "# Define on head for the policy\n",
        "policy_net = MLP(\n",
        "    in_features=common_mlp_output.shape[-1],\n",
        "    out_features=num_outputs,\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    num_cells=[256],\n",
        ")\n",
        "policy_module = TensorDictModule(\n",
        "    module=policy_net,\n",
        "    in_keys=[\"common_features\"],\n",
        "    out_keys=[\"logits\"],\n",
        ")\n",
        "\n",
        "# Add probabilistic sampling of the actions\n",
        "policy_module = ProbabilisticActor(\n",
        "    policy_module,\n",
        "    in_keys=[\"logits\"],\n",
        "    spec=CompositeSpec(action=env.action_spec),\n",
        "    # safe=True,\n",
        "    distribution_class=OneHotCategorical,\n",
        "    distribution_kwargs={},\n",
        "    return_log_prob=True,\n",
        "    default_interaction_type=ExplorationType.RANDOM,\n",
        ")\n",
        "\n",
        "# Define another head for the value\n",
        "value_net = MLP(\n",
        "    activation_class=torch.nn.ReLU,\n",
        "    in_features=common_mlp_output.shape[-1],\n",
        "    out_features=1,\n",
        "    num_cells=[256],\n",
        ")\n",
        "value_module = ValueOperator(\n",
        "    value_net,\n",
        "    in_keys=[\"common_features\"],\n",
        ")"
      ],
      "metadata": {
        "id": "Z7gPCBCUqIf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_critic = ActorValueOperator(\n",
        "    common_operator=common_module,\n",
        "    value_operator=value_module,\n",
        "    policy_operator=policy_module\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "dj5UygmTqKO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    td = env.rollout(max_steps=1000, break_when_any_done=False)\n",
        "    td = actor_critic(td)"
      ],
      "metadata": {
        "id": "muv30hWcqLp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    actor_critic.get_policy_operator(),\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "Q1iQvbHAqMc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "xREjzDFCqNi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma,\n",
        "    lmbda=lmbda,\n",
        "    value_network=actor_critic.get_value_operator(),\n",
        "    average_gae=True\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor=actor_critic.get_policy_operator(),\n",
        "    critic=actor_critic.get_value_head(),\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    value_target_key=advantage_module.value_target_key,\n",
        "    gamma=0.99,\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)"
      ],
      "metadata": {
        "id": "sYABG3CoqPHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "env.reset()\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                    loss_vals[\"loss_objective\"]\n",
        "                    + loss_vals[\"loss_critic\"]\n",
        "                    + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "\n",
        "   #  recorder.dump(f\"Episode_{i}\")\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, actor_critic.get_policy_operator())\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))"
      ],
      "metadata": {
        "id": "_jRcinbdqQgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JKmCfQyxqSpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}